# ğŸ§  {{ cookiecutter.project_name }}

{{ cookiecutter.description }}

---

## ğŸ“¦ Overview

This repository was created from the [ML Template](https://github.com/jainmilan/ml-template) â€” a standardized structure for reproducible ML and DL research projects.  

It includes:
- A clean directory layout for data, code, and outputs  
- Ready-to-use experiment management with **Hydra**  
- Integrated **Poetry** environment for reproducibility  
- Optional experiment tracking with **MLflow**  
- Built-in support for **Optuna** (hyperparameter optimization)

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Create the environment
```bash
poetry install
```

If you need deep learning support (PyTorch, Transformers, Lightning):
```bash
poetry install --with dl
```

Activate the environment:
```bash
poetry shell
```

---

### 2ï¸âƒ£ Explore the data
```bash
jupyter lab
```

You can start from notebooks under `code/notebooks/` to perform exploratory data analysis (EDA) or visualize processed data.

---

### 3ï¸âƒ£ Run training

The main training entry point is:

```bash
poetry run python code/src/training/train_model.py
```

You can customize experiments using **Hydra** configuration overrides, for example:
```bash
poetry run python code/src/training/train_model.py model=xgboost data=resstock train=default
```

Hydra automatically creates time-stamped output folders under `output/logs/` and can integrate with MLflow if configured.

---

### 4ï¸âƒ£ Track results

If MLflow tracking is enabled in your config (`output/mlflow/`):
- All metrics, parameters, and model artifacts are logged automatically  
- You can visualize runs with:
  ```bash
  poetry run mlflow ui --backend-store-uri output/mlflow
  ```

Then open [http://localhost:5000](http://localhost:5000) in your browser.

---

## ğŸ“‚ Project Structure

```
project/
â”œâ”€â”€ code/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ data/            # Data loading & preprocessing scripts
â”‚   â”‚   â”œâ”€â”€ models/          # ML or DL model definitions
â”‚   â”‚   â”œâ”€â”€ training/        # Training & evaluation logic
â”‚   â”‚   â”œâ”€â”€ utils/           # Helper functions & metrics
â”‚   â”‚   â””â”€â”€ visualization/   # Plotting utilities
â”‚   â”œâ”€â”€ conf/                # Hydra configuration files
â”‚   â”œâ”€â”€ notebooks/           # Exploratory analysis
â”‚   â”œâ”€â”€ scripts/             # CLI utilities, batch jobs
â”‚   â””â”€â”€ tests/               # Unit tests
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Immutable source data
â”‚   â”œâ”€â”€ interim/             # Cleaned/intermediate datasets
â”‚   â””â”€â”€ processed/           # Ready-to-model data
â”‚
â”œâ”€â”€ output/
â”‚   â”œâ”€â”€ logs/                # Hydra logs
â”‚   â”œâ”€â”€ mlflow/              # MLflow experiments
â”‚   â”œâ”€â”€ models/              # Saved models
â”‚   â”œâ”€â”€ predictions/         # Model predictions
â”‚   â””â”€â”€ figures/             # Generated visualizations
â”‚
â”œâ”€â”€ documents/               # Reports, references, notes
â”œâ”€â”€ presentations/           # Slide decks & figures
â”œâ”€â”€ submissions/             # Paper drafts, reviews
â”œâ”€â”€ pyproject.toml           # Poetry environment definition
â”œâ”€â”€ README.md
â””â”€â”€ Makefile                 # Common automation commands
```

---

## âš™ï¸ Configuration (Hydra)

Hydra makes it easy to manage configurations for:
- `data/` (dataset paths, splits)
- `model/` (architecture, hyperparameters)
- `train/` (epochs, batch size, early stopping)
- `eval/` (metrics, cross-validation)

Example `code/conf/config.yaml`:
```yaml
defaults:
  - data: resstock
  - model: xgboost
  - train: default

experiment_name: "building_energy_pred"
seed: 42
```

To override values on the fly:
```bash
python code/src/training/train_model.py train.batch_size=128 model.params.max_depth=5
```

---

## ğŸ§® Running Hyperparameter Sweeps

This project supports [Optuna](https://optuna.org/) for optimization via Hydra sweepers:

```bash
python code/src/training/train_model.py -m train.lr=0.001,0.01,0.1 train.batch_size=32,64
```

Results and best configurations are logged to MLflow.

---

## ğŸ“Š Outputs

All results are automatically organized under `output/`:

| Folder | Description |
|---------|--------------|
| `logs/` | Hydra run logs |
| `mlflow/` | Experiment tracking and metrics |
| `models/` | Trained model weights |
| `predictions/` | Generated predictions |
| `figures/` | Visualizations, plots, and reports |

---

## ğŸ§  Tips

- Keep all raw datasets under `data/raw/` (never modified manually).  
- Store processed or derived datasets under `data/processed/`.  
- Add any local paths or credentials to `.env` (not versioned).  
- Use `make setup`, `make run`, or `make clean` for quick automation.  
- Commit your `poetry.lock` file for reproducibility.

---

## ğŸ§¾ License

This project is distributed under the [MIT License](LICENSE).

---

## âœï¸ Author

**{{ cookiecutter.author_name }}**

Built using the [ML Template](https://github.com/jainmilan/ml-template)  
for reproducible research and AI model development.